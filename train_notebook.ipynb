{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], False)\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from loupe_keras import NetVLAD\n",
    "\n",
    "\n",
    "def get_imlist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith(u'.jpg')]\n",
    "\n",
    "\n",
    "def create_image_dict(img_list):\n",
    "    input_shape = (224, 224, 3)\n",
    "    tensor = {}\n",
    "    for path in img_list:\n",
    "        img = image.load_img(path, target_size=(input_shape[0], input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        img_key = path.strip('holidays_small/')\n",
    "        tensor[img_key] = img\n",
    "    # tensor = np.array(tensor)\n",
    "    return tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_dict = create_image_dict(get_imlist('holidays_small'))\n",
    "img_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "n_queries = 500\n",
    "\n",
    "# create dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "labeled_file = open(\"labeled.dat\", \"r\")\n",
    "for line in labeled_file.readlines():\n",
    "    split = line.split(\" \")[:3]\n",
    "\n",
    "    images.append(img_dict[split[0]])\n",
    "    label_index = int(split[2])\n",
    "    #label = np.zeros(n_queries)\n",
    "    #label[label_index] = 1.0\n",
    "    labels.append(label_index)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels).astype('int32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# create model\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# vgg = VGG16(weights='imagenet', include_top=False, pooling=False, input_shape=input_shape)\n",
    "vgg = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=input_shape)\n",
    "\n",
    "# set layers untrainable\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    # print(layer, layer.trainable)\n",
    "    #if layer.name is 'block5_conv3':\n",
    "    #    layer.trainable = True\n",
    "\n",
    "# vgg = Model(vgg.input, vgg.get_layer('block5_conv3').output)\n",
    "\n",
    "#vgg.layers.pop()\n",
    "# vgg.layers.pop(0)\n",
    "\n",
    "vgg.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Dropout, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from triplet_loss import L2NormLayer\n",
    "\n",
    "images_input = Input(shape=(224, 224, 3))\n",
    "label_input = Input(shape=(1,),name=\"input_label\")\n",
    "\n",
    "# transpose = Permute((3, 1, 2), input_shape=(-1, 512))\n",
    "embedding_size = 512\n",
    "\n",
    "vgg_output = vgg.output_shape[1]\n",
    "embedding = Dense(embedding_size, input_shape=(vgg_output,), activation='relu', name=\"embedding1\")(vgg([images_input]))\n",
    "reshape = Reshape((8, 8 * 8))(embedding)\n",
    "netvlad = NetVLAD(feature_size=8 * 8, max_samples=8, cluster_size=64,\n",
    "                  output_dim=1024)(reshape)  # , output_dim=1024)resnet_output = resnet.output_shape[1]\n",
    "\n",
    "netvlad_output = 8*8*64\n",
    "\n",
    "l2normalization = L2NormLayer()\n",
    "dropout = Dropout(0.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#embedding_output = netvlad(reshape(embedding(vgg.output)))\n",
    "labels_plus_embeddings = concatenate([label_input, netvlad])\n",
    "\n",
    "\n",
    "vgg_netvlad = Model(inputs=[images_input, label_input], outputs=labels_plus_embeddings)\n",
    "\n",
    "# %%\n",
    "\n",
    "plot_model(vgg_netvlad, to_file='base_network.png', show_shapes=True, show_layer_names=True)\n",
    "vgg_netvlad.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "result = vgg_netvlad.predict([images[:1], labels[:1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_data_len = len(img_dict.keys())\n",
    "#n_train = all_data_len\n",
    "#n_train = 500\n",
    "\n",
    "#fake_true_pred = np.zeros((n_train, embedding_size * 3))\n",
    "#fake_true_pred_val = np.zeros((all_data_len - n_train, embedding_size * 3))\n",
    "\n",
    "images_train = images[n_queries:]\n",
    "labels_train = labels[n_queries:]\n",
    "\n",
    "images_test = images[:n_queries]\n",
    "labels_test = labels[:n_queries]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fc052c097d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#loss_layer = TripletLossLayer(alpha=1., name='triplet_loss_layer')(vgg_netvlad.output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#vgg_qpn = Model(inputs=vgg_qpn.input, outputs=loss_layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mvgg_netvlad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_hard_triplet_loss_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdummy_gt_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetvlad_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     output_loss = loss_fn(\n\u001b[0;32m--> 692\u001b[0;31m                         y_true, y_pred, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/venv/lib/python3.6/site-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lambda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'<lambda>'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             return losses_utils.compute_weighted_loss(\n\u001b[1;32m     73\u001b[0m                 losses, sample_weight, reduction=self.reduction)\n",
      "\u001b[0;32m~/Documenti/netvlad/venv/lib/python3.6/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/triplet_loss_.py\u001b[0m in \u001b[0;36mbatch_hard_triplet_loss_k\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Get the pairwise distance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mpairwise_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msquared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# For each anchor, get the hardest positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/netvlad/triplet_loss_.py\u001b[0m in \u001b[0;36m_pairwise_distances\u001b[0;34m(embeddings, squared)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# This also provides more numerical stability (the diagonal of the result will be exactly 0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# shape (batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msquare_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Compute the pairwise distance matrix as we have:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'array_ops'"
     ],
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'array_ops'",
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = True\n",
    "if train:\n",
    "    #from triplet_loss_ import TripletLossLayer, triplet_loss_adapted_from_tf\n",
    "    from triplet_loss_ import batch_hard_triplet_loss_k\n",
    "    batch_size = 256\n",
    "    epochs = 64\n",
    "\n",
    "    # train session\n",
    "    opt = Adam(lr=0.0001)  # choose optimiser. RMS is good too!\n",
    "\n",
    "    #loss_layer = TripletLossLayer(alpha=1., name='triplet_loss_layer')(vgg_netvlad.output)\n",
    "    #vgg_qpn = Model(inputs=vgg_qpn.input, outputs=loss_layer)\n",
    "    vgg_netvlad.compile(optimizer=opt, loss=batch_hard_triplet_loss_k)\n",
    "\n",
    "    dummy_gt_train = np.zeros((len(images_train), netvlad_output + 1))\n",
    "    dummy_gt_val = np.zeros((len(images_test), netvlad_output + 1))\n",
    "\n",
    "    # %%\n",
    "\n",
    "    H = vgg_netvlad.fit(\n",
    "        x=[images_train, labels_train],\n",
    "        y=dummy_gt_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=([images_test, labels_test], dummy_gt_val),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    vgg_netvlad.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(H.history['loss'], label='training loss')\n",
    "    plt.plot(H.history['val_loss'], label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.title('Train/validation loss')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# pop triplet loss layer\n",
    "# resnet_qpn_no_loss = Model(input=resnet_qpn.input, outputs=resnet_qpn.output)\n",
    "# resnet_qpn_no_loss.layers.pop()\n",
    "# resnet_qpn_no_loss.summary()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# reload model from disk\n",
    "#vgg_qpn = Model([input_q, input_p, input_n], [embedding_q, embedding_p, embedding_n])\n",
    "\n",
    "#vgg_qpn.load_weights('model.h5')\n",
    "\n",
    "result = vgg_netvlad.predict([images[:1], labels[:1]])\n",
    "# %%\n",
    "\n",
    "# test model\n",
    "\n",
    "# this function create a perfect ranking :)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "\n",
    "def get_imlist_(path=\"holidays_small\"):\n",
    "    imnames = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(u'.jpg')]\n",
    "    imnames = [path.strip('holidays_small/') for path in imnames]\n",
    "    imnames = [path.strip('.jpg') for path in imnames]\n",
    "    return imnames\n",
    "\n",
    "\n",
    "def images_to_tensor(imnames):\n",
    "    images_array = []\n",
    "\n",
    "    # open all images\n",
    "    for name in imnames:\n",
    "        img_path = 'holidays_small/' + name + '.jpg'\n",
    "        img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n",
    "        img = image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        images_array.append(img)\n",
    "    images_array = np.array(images_array)\n",
    "    print(images_array.shape)\n",
    "    # images_array = preprocess_input(images_array)\n",
    "    return images_array\n",
    "\n",
    "\n",
    "imnames = get_imlist_()\n",
    "\n",
    "query_imids = [i for i, name in enumerate(imnames) if name[-2:].split('.')[0] == \"00\"]\n",
    "\n",
    "# check that everything is fine - expected output: \"tot images = 1491, query images = 500\"\n",
    "print('tot images = %d, query images = %d' % (len(imnames), len(query_imids)))\n",
    "\n",
    "# %%\n",
    "\n",
    "# img_tensor = images_to_tensor(imnames)\n",
    "img_tensor = [img_dict[key] for key in img_dict]\n",
    "img_tensor = np.array(img_tensor)\n",
    "\n",
    "# %%\n",
    "vgg_netvlad.summary()\n",
    "all_feats, _ = vgg_netvlad.predict([np.zeros(len(img_tensor)), img_tensor])\n",
    "\n",
    "plt.imshow(all_feats, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "\n",
    "query_feats = all_feats[query_imids]\n",
    "\n",
    "# SOLUTION\n",
    "nbrs = NearestNeighbors(n_neighbors=1491, metric='cosine').fit(all_feats)\n",
    "distances, indices = nbrs.kneighbors(query_feats)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def make_perfect_holidays_result(imnames, q_ids):\n",
    "    perfect_idx = []\n",
    "    for qimno in q_ids:\n",
    "        qname = imnames[qimno]\n",
    "        positive_results = set([i for i, name in enumerate(imnames) if name != qname and name[:4] == qname[:4]])\n",
    "        ok = [qimno] + [i for i in positive_results]\n",
    "        others = [i for i in range(1491) if i not in positive_results and i != qimno]\n",
    "        perfect_idx.append(ok + others)\n",
    "    return np.array(perfect_idx)\n",
    "\n",
    "\n",
    "def mAP(q_ids, idx):\n",
    "    aps = []\n",
    "    for qimno, qres in zip(q_ids, idx):\n",
    "        qname = imnames[qimno]\n",
    "        # collect the positive results in the dataset\n",
    "        # the positives have the same prefix as the query image\n",
    "        positive_results = set([i for i, name in enumerate(imnames)\n",
    "                                if name != qname and name[:4] == qname[:4]])\n",
    "        #\n",
    "        # ranks of positives. We skip the result #0, assumed to be the query image\n",
    "        ranks = [i for i, res in enumerate(qres[1:]) if res in positive_results]\n",
    "        #\n",
    "        # accumulate trapezoids with this basis\n",
    "        recall_step = 1.0 / len(positive_results)\n",
    "        ap = 0\n",
    "        for ntp, rank in enumerate(ranks):\n",
    "            # ntp = nb of true positives so far\n",
    "            # rank = nb of retrieved items so far\n",
    "            # y-size on left side of trapezoid:\n",
    "            precision_0 = ntp / float(rank) if rank > 0 else 1.0\n",
    "            # y-size on right side of trapezoid:\n",
    "            precision_1 = (ntp + 1) / float(rank + 1)\n",
    "            ap += (precision_1 + precision_0) * recall_step / 2.0\n",
    "        # print('query %s, AP = %.3f' % (qname, ap))\n",
    "        aps.append(ap)\n",
    "    return np.mean(aps)\n",
    "\n",
    "\n",
    "print('mean AP = %.3f' % mAP(query_imids, indices))\n",
    "perfect_result = make_perfect_holidays_result(imnames, query_imids)\n",
    "print('Perfect mean AP = %.3f' % mAP(query_imids, perfect_result))\n",
    "\n",
    "import PIL\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def montage(imfiles, thumb_size=(100, 100), ok=None, shape=None):\n",
    "    # this function will create an image with thumbnailed version of imfiles.\n",
    "    # optionally the user can provide an ok list such that len(ok)==len(imfiles) to differentiate correct from wrong results\n",
    "    # optionally the user can provide a shape function which shapes the montage otherwise a square image is created.\n",
    "    images = [PIL.Image.open(imname).resize(thumb_size, PIL.Image.BILINEAR) for imname in imfiles]\n",
    "    # create a big image to contain all images\n",
    "    if shape is None:\n",
    "        n = int(math.sqrt(len(imfiles)))\n",
    "        m = n\n",
    "    else:\n",
    "        n = shape[0]\n",
    "        m = shape[1]\n",
    "    new_im = PIL.Image.new('RGB', (m * thumb_size[0], n * thumb_size[0]))\n",
    "    k = 0\n",
    "    for i in range(0, n * thumb_size[0], thumb_size[0]):\n",
    "        for j in range(0, m * thumb_size[0], thumb_size[0]):\n",
    "            region = (j, i)\n",
    "            if ok is not None:\n",
    "                if ok[k]:\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    color = (255, 0, 0)\n",
    "                if k > 0:\n",
    "                    imar = np.array(images[k], dtype=np.uint8)\n",
    "                    imar[0:5, :, :] = color\n",
    "                    imar[:, 0:5, :] = color\n",
    "                    imar[-5:, :, :] = color\n",
    "                    imar[:, -5:, :] = color\n",
    "                    images[k] = PIL.Image.fromarray(imar)\n",
    "            new_im.paste(images[k], box=region)\n",
    "            k += 1\n",
    "    return new_im\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# here we show the first 25 queries and their 15 closest neighbours retrieved\n",
    "# gree border means ok, red wrong :)\n",
    "def show_result(display_idx, nqueries=10, nresults=10, ts=(100, 100)):\n",
    "    if nqueries is not None:\n",
    "        nrow = nqueries  # number of query images to show\n",
    "\n",
    "    if nresults is not None:\n",
    "        nres = 10  # number of results per query\n",
    "\n",
    "    for qno in range(nrow):\n",
    "        imfiles = []\n",
    "        oks = [True]\n",
    "        # show query image with white outline\n",
    "        qimno = query_imids[qno]\n",
    "        imfiles.append('holidays_small/' + imnames[qimno] + '.jpg')\n",
    "        for qres in display_idx[qno, :nres]:\n",
    "            # use image name to determine if it is a TP or FP result\n",
    "            oks.append(imnames[qres][:4] == imnames[qimno][:4])\n",
    "            imfiles.append('holidays_small/' + imnames[qres] + '.jpg')\n",
    "        print(qno, (imfiles))\n",
    "        plt.imshow(montage(imfiles, thumb_size=ts, ok=oks, shape=(1, nres)))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "show_result(indices, nqueries=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}